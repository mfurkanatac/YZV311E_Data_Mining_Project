{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU</td>\n",
       "      <td>Julius NM</td>\n",
       "      <td>2013-11-07T06:20:48</td>\n",
       "      <td>Huh, anyway check out this you[tube] channel: ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A</td>\n",
       "      <td>adam riyati</td>\n",
       "      <td>2013-11-07T12:37:15</td>\n",
       "      <td>Hey guys check out my new channel and our firs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8</td>\n",
       "      <td>Evgeny Murashkin</td>\n",
       "      <td>2013-11-08T17:34:21</td>\n",
       "      <td>just for test I have to say murdev.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z13jhp0bxqncu512g22wvzkasxmvvzjaz04</td>\n",
       "      <td>ElNino Melendez</td>\n",
       "      <td>2013-11-09T08:28:43</td>\n",
       "      <td>me shaking my sexy ass on my channel enjoy ^_^ ﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z13fwbwp1oujthgqj04chlngpvzmtt3r3dw</td>\n",
       "      <td>GsMega</td>\n",
       "      <td>2013-11-10T16:05:38</td>\n",
       "      <td>watch?v=vtaRGgvGtWQ   Check this out .﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    COMMENT_ID            AUTHOR  \\\n",
       "0  LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU         Julius NM   \n",
       "1  LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A       adam riyati   \n",
       "2  LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8  Evgeny Murashkin   \n",
       "3          z13jhp0bxqncu512g22wvzkasxmvvzjaz04   ElNino Melendez   \n",
       "4          z13fwbwp1oujthgqj04chlngpvzmtt3r3dw            GsMega   \n",
       "\n",
       "                  DATE                                            CONTENT  \\\n",
       "0  2013-11-07T06:20:48  Huh, anyway check out this you[tube] channel: ...   \n",
       "1  2013-11-07T12:37:15  Hey guys check out my new channel and our firs...   \n",
       "2  2013-11-08T17:34:21             just for test I have to say murdev.com   \n",
       "3  2013-11-09T08:28:43   me shaking my sexy ass on my channel enjoy ^_^ ﻿   \n",
       "4  2013-11-10T16:05:38            watch?v=vtaRGgvGtWQ   Check this out .﻿   \n",
       "\n",
       "   CLASS  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# merge files\n",
    "df1 = pd.read_csv('Youtube01-Psy.csv')\n",
    "df2 = pd.read_csv('Youtube02-KatyPerry.csv')\n",
    "df3 = pd.read_csv('Youtube03-LMFAO.csv')\n",
    "df4 = pd.read_csv('Youtube04-Eminem.csv')\n",
    "df5 = pd.read_csv('Youtube05-Shakira.csv')\n",
    "\n",
    "df = pd.concat([df1, df2, df3, df4, df5])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1005\n",
       "0     951\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['COMMENT_ID', 'AUTHOR', 'DATE'], axis=1, inplace=True)\n",
    "\n",
    "df.rename(columns={'CLASS': 'label', 'CONTENT': 'text'}, inplace=True)\n",
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms = pd.read_csv(\"SMSSpamCollection.txt\", sep='\\t', lineterminator='\\n', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms.columns = ['label', 'text']\n",
    "\n",
    "sms['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4825\n",
       "1     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "sms['label'] = le.fit_transform(sms['label'])\n",
    "\n",
    "sms[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, sms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5776\n",
       "1    1752\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Furkan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Furkan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag, word_tokenize\n",
    "import re\n",
    "\n",
    "# Download the required NLTK resources\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to lemmatize text\n",
    "def custom_lemmatizer(input_text):\n",
    "    # Tokenize the input text into individual words\n",
    "    words_list = word_tokenize(input_text)\n",
    "\n",
    "    # Create a list to store lemmatized words\n",
    "    lemmatized_list = []\n",
    "\n",
    "    # Iterate through each word and its POS tag\n",
    "    for word, tag in pos_tag(words_list):\n",
    "        # Determine the WordNet tag from the first character of the POS tag\n",
    "        wn_tag = tag[0].lower() if tag[0].lower() in ['a', 'r', 'n', 'v'] else None\n",
    "\n",
    "        # Lemmatize the word using the determined WordNet tag\n",
    "        lemma_word = lemmatizer.lemmatize(word, wn_tag) if wn_tag else word\n",
    "\n",
    "        # Append the lemmatized word to the list\n",
    "        lemmatized_list.append(lemma_word)\n",
    "\n",
    "    # Join the lemmatized words into a string and return\n",
    "    return \" \".join(lemmatized_list)\n",
    "\n",
    "\n",
    "# Function to remove special characters from the text\n",
    "def remove_special_char(text):\n",
    "    if not isinstance(text, str):\n",
    "        return str(text)  # Convert non-string data to string\n",
    "    \n",
    "    pattern = r\"[^a-zA-Z0-9\\s]\"\n",
    "    cleaned_text = re.sub(pattern, \"\", text)\n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.lower()\n",
    "\n",
    "df[\"cleaned-text\"] = df[\"text\"].apply(remove_special_char)\n",
    "df[\"cleaned-text\"] = df[\"cleaned-text\"].apply(custom_lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned-text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>huh, anyway check out this you[tube] channel: ...</td>\n",
       "      <td>1</td>\n",
       "      <td>huh anyway check out this youtube channel koby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hey guys check out my new channel and our firs...</td>\n",
       "      <td>1</td>\n",
       "      <td>hey guy check out my new channel and our first...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just for test i have to say murdev.com</td>\n",
       "      <td>1</td>\n",
       "      <td>just for test i have to say murdevcom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>me shaking my sexy ass on my channel enjoy ^_^ ﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>me shake my sexy as on my channel enjoy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watch?v=vtarggvgtwq   check this out .﻿</td>\n",
       "      <td>1</td>\n",
       "      <td>watchvvtarggvgtwq check this out</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  huh, anyway check out this you[tube] channel: ...      1   \n",
       "1  hey guys check out my new channel and our firs...      1   \n",
       "2             just for test i have to say murdev.com      1   \n",
       "3   me shaking my sexy ass on my channel enjoy ^_^ ﻿      1   \n",
       "4            watch?v=vtarggvgtwq   check this out .﻿      1   \n",
       "\n",
       "                                        cleaned-text  \n",
       "0  huh anyway check out this youtube channel koby...  \n",
       "1  hey guy check out my new channel and our first...  \n",
       "2              just for test i have to say murdevcom  \n",
       "3            me shake my sexy as on my channel enjoy  \n",
       "4                   watchvvtarggvgtwq check this out  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['text'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.899734395750332\n",
      "Confusion matrix: \n",
      " [[1132    2]\n",
      " [ 149  223]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94      1134\n",
      "           1       0.99      0.60      0.75       372\n",
      "\n",
      "    accuracy                           0.90      1506\n",
      "   macro avg       0.94      0.80      0.84      1506\n",
      "weighted avg       0.91      0.90      0.89      1506\n",
      "\n",
      "Accuracy score:  0.949535192563081\n",
      "Confusion matrix: \n",
      " [[1129    5]\n",
      " [  71  301]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      1134\n",
      "           1       0.98      0.81      0.89       372\n",
      "\n",
      "    accuracy                           0.95      1506\n",
      "   macro avg       0.96      0.90      0.93      1506\n",
      "weighted avg       0.95      0.95      0.95      1506\n",
      "\n",
      "Accuracy score:  0.952191235059761\n",
      "Confusion matrix: \n",
      " [[1128    6]\n",
      " [  66  306]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97      1134\n",
      "           1       0.98      0.82      0.89       372\n",
      "\n",
      "    accuracy                           0.95      1506\n",
      "   macro avg       0.96      0.91      0.93      1506\n",
      "weighted avg       0.95      0.95      0.95      1506\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# we will do Naive Bayes, Random Forest and SVM \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['cleaned-text']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"Classification report: \\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"Classification report: \\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"Classification report: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Failed here however others got a better result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9475431606905711\n",
      "Confusion matrix: \n",
      " [[1132    2]\n",
      " [  77  295]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      1134\n",
      "           1       0.99      0.79      0.88       372\n",
      "\n",
      "    accuracy                           0.95      1506\n",
      "   macro avg       0.96      0.90      0.92      1506\n",
      "weighted avg       0.95      0.95      0.95      1506\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensemble model\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "vc = VotingClassifier(estimators=[('nb', nb), ('rf', rf), ('svc', svc)], voting='hard')\n",
    "vc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = vc.predict(X_test)\n",
    "\n",
    "print(\"Accuracy score: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"Classification report: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "model.load_state_dict(torch.load('bert_model.pt'))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# predict youtube and sms spam\n",
    "\n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['cleaned-text'], df['label'], \n",
    "                                                                    random_state=2018, \n",
    "                                                                    test_size=0.1, \n",
    "                                                                    stratify=df['label'])\n",
    "\n",
    "# We'll further split the validation set into validation and test datasets\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
    "                                                                random_state=2018, \n",
    "                                                                test_size=0.3, \n",
    "                                                                stratify=temp_labels)\n",
    "\n",
    "test_encodings = tokenizer(test_text.tolist(), truncation=True, padding=True, max_length=256)\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "test_inputs = torch.tensor(test_encodings['input_ids'])\n",
    "test_labels = torch.tensor(test_labels.tolist())\n",
    "test_masks = torch.tensor(test_encodings['attention_mask'])\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "model.load_state_dict(torch.load('bert_model.pt'))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have test_dataloader defined and ready to use\n",
    "\n",
    "def evaluate_test_set(test_dataloader, top_n):\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Tell the model not to compute or store gradients\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "\n",
    "        logits = outputs.logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Get the top N predictions with probabilities for each sample in the batch\n",
    "        top_n_indices = np.argsort(logits, axis=1)[:, -top_n:][:, ::-1]\n",
    "        top_n_probs = np.take_along_axis(logits, top_n_indices, axis=1)\n",
    "\n",
    "        # Convert the predicted indices and probabilities to their corresponding labels\n",
    "        batch_predictions = []\n",
    "        for sample_probs, sample_indices in zip(top_n_probs, top_n_indices):\n",
    "            sample_predictions = [\n",
    "                (label_id, prob) for label_id, prob in zip(sample_indices, sample_probs)\n",
    "            ]\n",
    "            batch_predictions.append(sample_predictions)\n",
    "\n",
    "        predictions.extend(batch_predictions)\n",
    "        true_labels.extend(label_ids)\n",
    "\n",
    "        # Check if the true label is in the top N predictions\n",
    "        for sample_preds, true_label_id in zip(batch_predictions, label_ids):\n",
    "            if true_label_id in [pred_label_id for pred_label_id, _ in sample_preds]:\n",
    "                correct_predictions += 1\n",
    "\n",
    "    total_samples = len(test_dataloader.dataset)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "\n",
    "    return predictions, true_labels, accuracy\n",
    "\n",
    "# Call the function to get the top 3 predictions with probabilities and calculate accuracy\n",
    "predictions, true_labels, accuracy = evaluate_test_set(test_dataloader, top_n=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8495575221238938\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without training the model specialized for the task, BERT cannot see ahead. BERT is powerful within the specific borders drawn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
